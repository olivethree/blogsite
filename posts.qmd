---
title: "Posts"
---

## Hi, my name is...

I wrote this piece for those who have an interest in learning a bit about me and my professional traject so far.

I love coffee and would ideally invite you to join me for a cup (other beverages allowed, naturally!). To compensate, here's a picture of a morning coffee scene to get you in the mood to read the rest of the monologue:

![Retrieved from: pexels.com](assets/pexels-gagan-cambow-1170659.jpg){fig-align="center" width="500"}

In 2019, I earned my PhD in Social Psychology from ISPA - Instituto Universitario. During my PhD I divided my time between Portugal and the Netherlands, conducting research at [William James Center for Research](https://williamjamescr.org/) and [Utrecht University](https://www.uu.nl/en/research/behaviour-in-social-context/research-programmes/social-cognitive-and-interpersonal-determinants-of-behaviour).

![Moments after I survived my Ph.D. defense ðŸ˜„](assets/phd_defense_manueloliveira.jpg){fig-align="center" width="500"}

My doctoral work resulted in multiple scientific contributions to the fields of social perception and psychophysical image classification methods (a.k.a. reverse-correlation).

After obtaining my PhD, I moved into industry in pursuit of research with a more direct societal impact. I believe that goal was achieved during the time I spent doing research to support the development of automated clinical decision support software. At the same time, it became clear to me that there was not yet enough knowledge available to inform many of the steps taken during the development of automated systems that directly impact the human side of the human-computer interaction. Questions such as "How much control should we give to the user?", "How are human biases being taken into account into the development of these automated tools?", "What factors promote trust between user and AI systems?", remained without a clear answer.

These and other questions made me realize that I should move back to the only domain in society where I believe there is time to clarify such questions: academia. I was lucky enough to find a team of researchers who welcomed me back into the ivory tower. Currently, I'm working as a postdoctoral researcher at Utrecht University in the team of Ruud Hortensius, Baptist Liefooghe, and Henk Aarts, on topics related with those questions or Human-centered Artificial Intelligence research in general.

In my free time, I enjoy playing music, brewing coffee, JRPGs, ocasionally go bouldering with friends, or take relaxed strolls in nature. And when time is no less than abundant, maybe play around with hobby projects (see [Apps](apps.qmd)).

## **Why behavioral science should guide AI development**

As I see it, knowledge about human psychology and behavior should be the guiding light in the development of smart tools (or AI tools if you prefer) serving society and people. It is my belief that a human-centered approach to AI development will not only catalyze progress in most societal domains, but also boost the competitiveness of entrepreneurial ventures invested in the crucial task of translating the promises of AI into more tangible products and services.

Importantly, I believe that we should raise awareness in the AI development community about all the harmful human biases that have hindered human progress to this day (e.g. prejudice of any kind). Therefore, I firmly defend we should find better ways of educating our "AI" systems, by preventing biased artificial behavior as much as we can.

Finally, although I've been mostly ranting about how psychological science benefits AI development, this collaboration is a win-win for both parties. Psychology and related behavioral sciences have much to learn about how the dawn of AI in our society is impacting human behavior and mental processes. For instance, "Are smart tools making us lazier?", "How is our memory being affected by smart tools?", "How is AI impacting our mental and behavioral development across the life-span?", among many other interesting questions one can start to think of -- psst...if you're interested in the future of AI, I recommend reading "[Human Compatible](https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS)" by Stuart Russell ðŸ˜‰. It is my hope that the attempts to answer such questions will throw light on the malleability of our behavior and mind processes during sigificant environmental changes, as well as expose a bit more of what pieces of our mental and behavioral *machinery* remain stoically invariant throughout the tides of time and progress.

**Date:** *19 August 2022*

**Author:** [M. Oliveira](about.qmd)
